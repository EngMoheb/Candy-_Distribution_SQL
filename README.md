# ğŸ­Candy-Distribution_SQLğŸ­
![ Cover](Assets/Profile.jpg)

## ğŸ“Œ About the Project
This project explores a real-world dataset about the US candy industry. We uploaded the CSV files into VS Code, created a PostgreSQL database, and established a connection between them. Also we build a clean database foundation and prepare the data to answer key business questions about candy sales, factory efficiency, and regional trends.

---
## ğŸ¯ Objectives
In this project, our main objectives are:

- âœ… Understand and structure the US Candy sales data.  
- âœ… Solve real business problems by identifying profitable products, comparing sales to targets, and providing advanced data analysis.
- âœ… Explore seasonality and regional trends in candy sales.  
- âœ… Compare product performance against division targets.  
- âœ… Build a maintainable, clean database schema with a clear ER diagram.
- âœ… Uncover data trends and hidden insights using advanced SQL techniques.
---

## ğŸ—‚ï¸ Data Source & Context
**_SourceğŸ‘‰_**: [**Maven Analytics â€œUS Candy Distributorâ€**](https://www.mavenanalytics.io/data-playground?order=date_added%2Cdesc&search=candy%20distributor)



**Why This Candy Dataset?**
 
- **Balanced Size:** Ideal for both complex SQL queries and rapid iteration.
- **Geospatial & Time Series Data:** Includes latitude/longitude coordinates, order dates, and shipping information, ideal for joins, distance calculations, and time-based analyses.
- **Business Relevance:** SKU-level sales data, factory origins, customer locations, and division targets mirror real-world retail/distribution analytics scenarios.
- **Well-Organised CSV Files:** Multiple files represent distinct tables in a relational model.


_**Here is a short description for each CSV file & its columns**_:

1.**Sales.csv**  
   - **Columns**: `row_id`, `order_id`, `order_date`, `ship_date`, `customer_id`,  
     `division`, `product_id`, `units`, `gross_profit`, `cost`, etc.  
   - **Describes**: Individual sales transactions linking customers, products, and financials.

2.  **Factories.csv**  
   - **Columns**: `factory_name`, `latitude`, `longitude`  
   - **Describes**: Candy factory names and their geographic locations.

3. **Targets.csv**  
   - **Columns**: `division`, `Target_Count`  
   - **Describes**: Sales targets for each division (Chocolate, Sugar, Other).

4.  **Products.csv**  
   - **Columns**: `product_id`, `product_name`, `division`, `factory_name`, `unit_cost`, `unit_price`  
   - **Describes**:  type of candy and  its division, factory origin, and cost/price.

5. **us_zips.csv**  
   - **Columns**: `zip`, `lat`, `lng`, `city`, `state_id`, `state_name`,  
     `zcta`, `population`, `density`, `county_fips`, `county_name`, `timezone`  
   - **Describes**: ZIP-level geographic and demographic data for mapping customers.

6. **Dictionary.csv**
   
    _Lists descriptions for the tables & their columns._

---  dinner

> **_Now let's move into the deep workğŸ•µï¸â€â™‚ï¸_**

## ğŸ“‘ Phase 1: Business & Data Understanding
- âœ… **Created** the PostgreSQL database and defined tables matching our CSV structures.  
- âœ… **Uploaded** CSV data into those tables using VS Codeâ€™s SQL editor.
- âœ… Verified row counts for each table matched CSV sources.  
- ğŸ§¹ Dropped unused columns from `us_zips` to keep only zip, zcta, state, county, population, density, timezone.   
- âœ… **Clarified** the business questions weâ€™ll answer by analysing our dataset:

 **General Analysis**

1. Which categories & products generate the highest profits?  
2. What are the top-selling categories & products by quantity?  
3. Which shipping routes are the most expensive?

**Geographic & Optimization**

1. Which customerâ€“factory pairs are least efficient (long distance + low margin)?  
2. Are there specific states/regions with higher return on sales?

**Time-Based Trends**

1. How do monthly/quarterly sales trends look?  
2. Are there specific weekdays or weekends with higher volume or profit?

**Advanced Insights**

1. Who are the topâ€¯5 Customers Over Time?
2. How has profit changed over time for each category?
3. Which product lines should be moved to a different factory to optimize shipping routes?
   


### ğŸ”— ERD Diagram
    FACTORIES ||--o{ PRODUCTS       : factory_name
    TARGETS   ||--o{ PRODUCTS       : division
    TARGETS   ||--o{ SALES          : division
    PRODUCTS  ||--o{ SALES          : product_id
    US_ZIPS   ||--o{ SALES          : postal_code


### ERD Explained

- **FACTORIES â†’ PRODUCTS** (`products.factory_name` â†’ `factories.factory_name`)  
  One factory can produce many products.

- **TARGETS â†’ PRODUCTS** (`products.division` â†’ `targets.division`)  
  Each product belongs to a division that has a sales target.

- **TARGETS â†’ SALES** (`sales.division` â†’ `targets.division`)  
  Each sale is classified under a division with an associated target.

- **PRODUCTS â†’ SALES** (`sales.product_id` â†’ `products.product_id`)  
  A product can appear in many sales records.

- **US_ZIPS â†’ SALES** (`sales.postal_code` â†’ `us_zips.zip`)  
  Each saleâ€™s customer ZIP links to geographic data.


---

## ğŸ› ï¸ Tools Used

- **PostgreSQL** â€“ Relational database for storing and querying data.  
- **VS Code** â€“ IDE for writing SQL, managing CSVs, and connecting to the database.  
- **Git & GitHub** â€“ Version control and documentation of the entire process.  
- **Sider AI** â€“  Explored multiple AI models for the data analysis journey. 
- **DeepSeek** â€“ Automated code review & best-practice suggestions.  
- **Perplexity** â€“ Contextual search for technical guidance & fact-checking.
- **GPT**â€“  Drafted and refined narrative content
- **Grammarly** â€“ Writing assistant to polish documentation.  

---
 
# **Phase:** 2 of 3  ğŸ§¹ Data Cleaning & Preparation 
 

## ğŸ” Overview

During **Phase 2**, we cleaned and prepared 5 core tables:

- **`factories`**  
- **`targets`**  
- **`products`**  
- **`us_zips`**  
- **`sales`**

For each table, we:

1. **âœ…Validated Data Types & Removed Nulls / Invalid Values**  
2. **âœ‚ï¸Trimmed Whitespace & Normalized text casing**  
3. **ğŸ“ Checked ranges for numeric & date columns**  
4. **ğŸ” Ensured uniqueness & removed duplicates**  
5. **ğŸ”— Enforced foreign key integrity relationships**  
6. **âš¡ Created indexes to boost query performance**

---

## âœ¨ Data Spa Treatment  
### ğŸ“ Text Columns  
- Identified and resolved missing values like hidden chocolate ğŸ«
- Removed extra spaces from all text fields âœ‚ï¸ 
- Standardized capitalization â€” no more SHOUTING or whispering ğŸ—£ï¸

### ğŸ”¢ Numeric Columns  
- Eliminated negative valuesğŸš«
- âš–ï¸ erified geographic coordinates: Confirmed coordinates were Earth-bound ğŸŒ and prices validity â‰¥ $0
-ğŸš©Flagged unusual values for review 

### ğŸ“… Date Columns  
- Removed time-traveling shipments (1930s orders? Not happening!)
- Ensured logical date sequences (ship after order)   
- Flagged unrealistic dates (like candy deliveries from the year 3000 ğŸš€) 

### âœ”ï¸ Boolean Columns  
- Replaced ambiguous entries with clear TRUE/FALSE values  
- Verified categorical consistency

---

## ğŸ§© Table-by-Table Transformation  

### ğŸ­ Factories Table  
- ğŸ·ï¸ Standardized naming conventions  ("sweet FACTORY" â†’ "Sweet Factory")
- ğŸŒ Validated geographic coordinates 
- ğŸ”‘ Ensured each factory had a unique ID 

### ğŸ¯ Targets Table  
- ğŸ“ŠCleaned division names 
- ğŸ¯ Validated targets to ensure all values were â‰¥ $0
- ğŸš«Eliminated duplicate divisions  â€” one division, one target

### ğŸ¬ Products Table  
- ğŸ†” **Standardized product IDs** ("choc-123" â†’ "CHOC-123")
- ğŸ’° **Flagged invalid pricing** (no negative costs!) 
- ğŸ¤ **Fixed foreign keys** â€” every product matched to a valid factory and division

### ğŸ“® US Zips Table  
-**ğŸ—ºï¸ Standardized geographic names** ("nEw yOrk" â†’ "New York")
- **ğŸ§® Verified population densities** were realistic
- ğŸ‘ª **Fixed parent-child** ZIP relationships where needed

### ğŸ’° Sales Table  
- ğŸ•°ï¸ **Removed 1930 shipments** that broke the space-time continuum
- ğŸ“¦ **Added delivery  time metrics** -  delivery days + delivery categories  (Q1, Q2, Q3, Q4)  
- ğŸ’¸**Flagged financial inconsistencies** (negative profits? Free candy?)  
- ğŸš¢ **Cleaned up shipping modes** â€” removed invalid entries like "Same Day"
  
  ## ğŸ•°ï¸ Special Case: 1930 Shipments  
**The Mystery:**Some orders claimed to ship _before_ they were placed!
**Findings:**  
- ğŸ“…  56 records dated to 1930  
- ğŸ•°ï¸ Ship dates < order dates  
**Resolution:**  
- ğŸ—‘ï¸ Deleted all impossible records
- ğŸ” Implemented delivery metrics to prevent similar issues in the future
**Why?** Like stale candy, bad data spoils everything!  

---

## ğŸ”— Relationship Counseling (Foreign Keys)  
We resolved the connectivity between related tables:
-  **ğŸ›Ÿ Rescued 427 sales** linked to missing products
- **ğŸ“¬ Repaired ZIP code gaps**
-  **ğŸ·ï¸ Ensured all products matched to valid division**
- **Reconnected orphaned data entries to their parent tables**.
> *"Like matching candy to wrappers - every piece belongs somewhere!"*  
---

## âš¡ Performance Optimization 
**Added 15 critical indexes to improve query speed**  
- **â±ï¸ Dramatically improved query speed for future deep analysis** 
- **ğŸ¢â†’âš¡Transformed slow operations**  

> *Without indexes, queries crawl like caramel spills... ğŸŒ
---

## ğŸ‰ Results
_After our data spa care, we_: 
- ğŸª¥ Scrubbed 10,000+  fields  
- ğŸ”— Repaired 427 relationships 
- ğŸš€ Added 15 performance-boosting indexes
- ğŸ—‘ï¸ 56 invalid records removed 

 **_Our data is now_**:
âœ… Consistent
âœ… Relational
âœ… Analysis-Ready 

 
> *"Clean data is like premium chocolate â€” pure, smooth, and deeply  satisfying!"** 

---
â¡ï¸ Next Steps: Analysis Phase!
With our dataset cleaned and polished, weâ€™re ready to:

- ğŸ« Uncover regional sales trends
- ğŸ“ˆ  Identify top-performing products
- ğŸšš Optimize delivery operations
- ğŸ¯ Evaluate sales target performance

  **Let the sweet insights flow!** ğŸ¬âœ¨

---

# **Phase:** 3 of 3  EDA & Advanced Analysis

## ğŸ§  SQL_Skills_Used

- **Joins** across multiple tables  
- **CASE** statements for conditional logic  
- **Common Table Expressions (CTEs)** for modular queries  
- **Window Functions** for running totals and rankings  
- **Data Cleaning:** null handling, formatting  
- **Pivoting** via CASE for cross-tabs  
- **Date/Time Functions** for extracting year/quarter/week  
- **Views** to encapsulate reusable queries  
- **Query Optimization** with indexes and EXPLAIN  

---

